{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n"
     ]
    }
   ],
   "source": [
    "mnistx = np.load('../data/mnist.npz')\n",
    "x,y = mnistx['x_train'],mnistx['y_train']\n",
    "x_val,y_val = mnistx['x_test'],mnistx['y_test']\n",
    "print('datasets:',x.shape,y.shape,x.min(),x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tf.convert_to_tensor(x,dtype=tf.float32)/255.\n",
    "db = tf.data.Dataset.from_tensor_slices((xs,y))\n",
    "db = db.batch(batch_size).repeat(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([layers.Dense(256,activation='relu'),\n",
    "                   layers.Dense(128,activation='relu'),\n",
    "                   layers.Dense(10)])\n",
    "model.build(input_shape=(4,28*28))\n",
    "model.summary()\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "acc_meter = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 1.840341329574585 acc: 0.03125\n",
      "200 loss: 0.4670301377773285 acc: 0.66734374\n",
      "400 loss: 0.3423806130886078 acc: 0.8389062\n",
      "600 loss: 0.36635205149650574 acc: 0.8565625\n",
      "800 loss: 0.28271153569221497 acc: 0.8871875\n",
      "1000 loss: 0.3174542784690857 acc: 0.885625\n",
      "1200 loss: 0.3056131601333618 acc: 0.9039062\n",
      "1400 loss: 0.22257688641548157 acc: 0.9146875\n",
      "1600 loss: 0.22300714254379272 acc: 0.9078125\n",
      "1800 loss: 0.21345525979995728 acc: 0.9253125\n",
      "2000 loss: 0.2243383526802063 acc: 0.93875\n",
      "2200 loss: 0.15718558430671692 acc: 0.929375\n",
      "2400 loss: 0.27255016565322876 acc: 0.9278125\n",
      "2600 loss: 0.22062839567661285 acc: 0.9351562\n",
      "2800 loss: 0.14155571162700653 acc: 0.9326562\n",
      "3000 loss: 0.2083386927843094 acc: 0.9334375\n",
      "3200 loss: 0.1914547085762024 acc: 0.93703127\n",
      "3400 loss: 0.13000856339931488 acc: 0.93421876\n",
      "3600 loss: 0.12920421361923218 acc: 0.935\n",
      "3800 loss: 0.1752210110425949 acc: 0.9529688\n",
      "4000 loss: 0.22880887985229492 acc: 0.9475\n",
      "4200 loss: 0.16257014870643616 acc: 0.93890625\n",
      "4400 loss: 0.16118651628494263 acc: 0.94609374\n",
      "4600 loss: 0.1778085082769394 acc: 0.94484377\n",
      "4800 loss: 0.1487625241279602 acc: 0.94109374\n",
      "5000 loss: 0.16071510314941406 acc: 0.9475\n",
      "5200 loss: 0.2566453218460083 acc: 0.9425\n",
      "5400 loss: 0.22417575120925903 acc: 0.94390625\n",
      "5600 loss: 0.10717184096574783 acc: 0.9571875\n",
      "5800 loss: 0.19701328873634338 acc: 0.95640624\n",
      "6000 loss: 0.14072048664093018 acc: 0.94984376\n",
      "6200 loss: 0.19679579138755798 acc: 0.9454687\n",
      "6400 loss: 0.11660157144069672 acc: 0.9525\n",
      "6600 loss: 0.13363425433635712 acc: 0.9496875\n",
      "6800 loss: 0.1097453385591507 acc: 0.94953126\n",
      "7000 loss: 0.12774792313575745 acc: 0.953125\n",
      "7200 loss: 0.3080029785633087 acc: 0.9446875\n",
      "7400 loss: 0.14012935757637024 acc: 0.955\n",
      "7600 loss: 0.15895134210586548 acc: 0.96625\n",
      "7800 loss: 0.10475341975688934 acc: 0.95515627\n",
      "8000 loss: 0.16258744895458221 acc: 0.954375\n",
      "8200 loss: 0.09750398248434067 acc: 0.959375\n",
      "8400 loss: 0.08822397887706757 acc: 0.9534375\n",
      "8600 loss: 0.13511329889297485 acc: 0.9534375\n",
      "8800 loss: 0.16253559291362762 acc: 0.9571875\n",
      "9000 loss: 0.13444456458091736 acc: 0.95265627\n",
      "9200 loss: 0.0815482884645462 acc: 0.95515627\n",
      "9400 loss: 0.0867389515042305 acc: 0.9684375\n",
      "9600 loss: 0.18855299055576324 acc: 0.963125\n",
      "9800 loss: 0.061897777020931244 acc: 0.9584375\n",
      "10000 loss: 0.1680006980895996 acc: 0.95921874\n",
      "10200 loss: 0.1337602138519287 acc: 0.9578125\n",
      "10400 loss: 0.1353078931570053 acc: 0.9546875\n",
      "10600 loss: 0.09765215963125229 acc: 0.9632813\n",
      "10800 loss: 0.19945794343948364 acc: 0.956875\n",
      "11000 loss: 0.10208183526992798 acc: 0.9565625\n",
      "11200 loss: 0.11645087599754333 acc: 0.9635937\n",
      "11400 loss: 0.11523505300283432 acc: 0.9689062\n",
      "11600 loss: 0.17047595977783203 acc: 0.96375\n",
      "11800 loss: 0.09121722728013992 acc: 0.96125\n",
      "12000 loss: 0.08647428452968597 acc: 0.96296877\n",
      "12200 loss: 0.09685016423463821 acc: 0.96125\n",
      "12400 loss: 0.15155810117721558 acc: 0.96203125\n",
      "12600 loss: 0.19906455278396606 acc: 0.9596875\n",
      "12800 loss: 0.1332690715789795 acc: 0.96\n",
      "13000 loss: 0.10112427175045013 acc: 0.963125\n",
      "13200 loss: 0.18021051585674286 acc: 0.97234374\n",
      "13400 loss: 0.09642799198627472 acc: 0.9660938\n",
      "13600 loss: 0.10363651812076569 acc: 0.9653125\n",
      "13800 loss: 0.10275417566299438 acc: 0.96421874\n",
      "14000 loss: 0.0660649985074997 acc: 0.96375\n",
      "14200 loss: 0.212785542011261 acc: 0.96375\n",
      "14400 loss: 0.11090526729822159 acc: 0.965\n",
      "14600 loss: 0.1785486936569214 acc: 0.95953125\n",
      "14800 loss: 0.08197610080242157 acc: 0.9639062\n",
      "15000 loss: 0.09485363215208054 acc: 0.97328126\n",
      "15200 loss: 0.11001694202423096 acc: 0.970625\n",
      "15400 loss: 0.09304472804069519 acc: 0.9664062\n",
      "15600 loss: 0.10965456068515778 acc: 0.96703124\n",
      "15800 loss: 0.09823223203420639 acc: 0.96625\n",
      "16000 loss: 0.12924347817897797 acc: 0.96296877\n",
      "16200 loss: 0.1093217134475708 acc: 0.966875\n",
      "16400 loss: 0.09130239486694336 acc: 0.96625\n",
      "16600 loss: 0.08573399484157562 acc: 0.96203125\n",
      "16800 loss: 0.10478812456130981 acc: 0.9690625\n",
      "17000 loss: 0.11926905810832977 acc: 0.9746875\n",
      "17200 loss: 0.048747383058071136 acc: 0.9690625\n",
      "17400 loss: 0.11874498426914215 acc: 0.96921873\n",
      "17600 loss: 0.11206880956888199 acc: 0.96875\n",
      "17800 loss: 0.059877872467041016 acc: 0.9664062\n",
      "18000 loss: 0.09863811731338501 acc: 0.968125\n",
      "18200 loss: 0.10377299785614014 acc: 0.96734375\n",
      "18400 loss: 0.0708950012922287 acc: 0.96703124\n",
      "18600 loss: 0.07149899750947952 acc: 0.9675\n",
      "18800 loss: 0.09672871232032776 acc: 0.974375\n",
      "19000 loss: 0.11930956691503525 acc: 0.9739063\n",
      "19200 loss: 0.07056784629821777 acc: 0.96953124\n",
      "19400 loss: 0.08553636819124222 acc: 0.9709375\n",
      "19600 loss: 0.12111424654722214 acc: 0.96703124\n",
      "19800 loss: 0.07299935072660446 acc: 0.96984375\n",
      "20000 loss: 0.07641394436359406 acc: 0.97\n",
      "20200 loss: 0.1686897724866867 acc: 0.96671873\n",
      "20400 loss: 0.1713341772556305 acc: 0.970625\n",
      "20600 loss: 0.045530881732702255 acc: 0.97578126\n",
      "20800 loss: 0.12159150838851929 acc: 0.9735938\n",
      "21000 loss: 0.093939870595932 acc: 0.97203124\n",
      "21200 loss: 0.11803781241178513 acc: 0.9717187\n",
      "21400 loss: 0.05826897546648979 acc: 0.9709375\n",
      "21600 loss: 0.055654771625995636 acc: 0.9703125\n",
      "21800 loss: 0.05224888026714325 acc: 0.97046876\n",
      "22000 loss: 0.07218478620052338 acc: 0.970625\n",
      "22200 loss: 0.23047150671482086 acc: 0.9675\n",
      "22400 loss: 0.0940937027335167 acc: 0.97234374\n",
      "22600 loss: 0.11239784955978394 acc: 0.9795312\n",
      "22800 loss: 0.06278511881828308 acc: 0.97234374\n",
      "23000 loss: 0.086891308426857 acc: 0.9735938\n",
      "23200 loss: 0.053442515432834625 acc: 0.9734375\n",
      "23400 loss: 0.04761265590786934 acc: 0.9703125\n",
      "23600 loss: 0.08419333398342133 acc: 0.97328126\n",
      "23800 loss: 0.1089925616979599 acc: 0.9714062\n",
      "24000 loss: 0.09402468800544739 acc: 0.9696875\n",
      "24200 loss: 0.040790021419525146 acc: 0.97234374\n",
      "24400 loss: 0.044595442712306976 acc: 0.97875\n",
      "24600 loss: 0.11703798174858093 acc: 0.978125\n",
      "24800 loss: 0.0286549124866724 acc: 0.9735938\n",
      "25000 loss: 0.11535388231277466 acc: 0.975\n",
      "25200 loss: 0.09306339174509048 acc: 0.9735938\n",
      "25400 loss: 0.10537230223417282 acc: 0.9721875\n",
      "25600 loss: 0.062394965440034866 acc: 0.97546875\n",
      "25800 loss: 0.14642098546028137 acc: 0.971875\n",
      "26000 loss: 0.0666116401553154 acc: 0.97015625\n",
      "26200 loss: 0.08653011173009872 acc: 0.9767187\n",
      "26400 loss: 0.061560939997434616 acc: 0.98046875\n",
      "26600 loss: 0.13781124353408813 acc: 0.97546875\n",
      "26800 loss: 0.06244996190071106 acc: 0.9753125\n",
      "27000 loss: 0.05111953988671303 acc: 0.9746875\n",
      "27200 loss: 0.05662258341908455 acc: 0.9753125\n",
      "27400 loss: 0.10877205431461334 acc: 0.97484374\n",
      "27600 loss: 0.12281295657157898 acc: 0.9715625\n",
      "27800 loss: 0.09019184112548828 acc: 0.9735938\n",
      "28000 loss: 0.0812363475561142 acc: 0.9739063\n",
      "28200 loss: 0.13342374563217163 acc: 0.98\n",
      "28400 loss: 0.06343314796686172 acc: 0.97796875\n",
      "28600 loss: 0.0668797492980957 acc: 0.9767187\n",
      "28800 loss: 0.08443969488143921 acc: 0.97625\n",
      "29000 loss: 0.03991654887795448 acc: 0.9759375\n",
      "29200 loss: 0.17453685402870178 acc: 0.97765625\n",
      "29400 loss: 0.08583609759807587 acc: 0.97546875\n",
      "29600 loss: 0.14577415585517883 acc: 0.9725\n",
      "29800 loss: 0.06065316125750542 acc: 0.974375\n",
      "30000 loss: 0.06074398756027222 acc: 0.98046875\n",
      "30200 loss: 0.07046067714691162 acc: 0.9796875\n",
      "30400 loss: 0.07234382629394531 acc: 0.9759375\n",
      "30600 loss: 0.07204066216945648 acc: 0.97875\n",
      "30800 loss: 0.0641169622540474 acc: 0.9771875\n",
      "31000 loss: 0.08600557595491409 acc: 0.9753125\n",
      "31200 loss: 0.07575364410877228 acc: 0.97796875\n",
      "31400 loss: 0.066896952688694 acc: 0.97703123\n",
      "31600 loss: 0.06172109767794609 acc: 0.9728125\n",
      "31800 loss: 0.08472773432731628 acc: 0.97875\n",
      "32000 loss: 0.08342930674552917 acc: 0.98265624\n",
      "32200 loss: 0.030412660911679268 acc: 0.976875\n",
      "32400 loss: 0.08024945855140686 acc: 0.98\n",
      "32600 loss: 0.07829076051712036 acc: 0.9767187\n",
      "32800 loss: 0.04605897143483162 acc: 0.97828126\n",
      "33000 loss: 0.06838121265172958 acc: 0.979375\n",
      "33200 loss: 0.07954932749271393 acc: 0.97734374\n",
      "33400 loss: 0.059458307921886444 acc: 0.9771875\n",
      "33600 loss: 0.05431945621967316 acc: 0.975625\n",
      "33800 loss: 0.07074079662561417 acc: 0.98234373\n",
      "34000 loss: 0.07501552999019623 acc: 0.9815625\n",
      "34200 loss: 0.04716296121478081 acc: 0.97828126\n",
      "34400 loss: 0.06578588485717773 acc: 0.97984374\n",
      "34600 loss: 0.09712518751621246 acc: 0.9771875\n",
      "34800 loss: 0.05731293186545372 acc: 0.9795312\n",
      "35000 loss: 0.05488689988851547 acc: 0.979375\n",
      "35200 loss: 0.11432770639657974 acc: 0.97625\n",
      "35400 loss: 0.13427239656448364 acc: 0.97765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35600 loss: 0.02910851687192917 acc: 0.98296875\n",
      "35800 loss: 0.08281341195106506 acc: 0.9815625\n",
      "36000 loss: 0.06775905191898346 acc: 0.97859377\n",
      "36200 loss: 0.09053294360637665 acc: 0.98125\n",
      "36400 loss: 0.04121784120798111 acc: 0.9803125\n",
      "36600 loss: 0.034611914306879044 acc: 0.9792187\n",
      "36800 loss: 0.03272838890552521 acc: 0.97984374\n",
      "37000 loss: 0.04326413571834564 acc: 0.97875\n",
      "37200 loss: 0.18887025117874146 acc: 0.9764063\n",
      "37400 loss: 0.07659545540809631 acc: 0.98\n",
      "37600 loss: 0.08551669120788574 acc: 0.9853125\n",
      "37800 loss: 0.042726244777441025 acc: 0.97984374\n",
      "38000 loss: 0.06473325937986374 acc: 0.9817188\n",
      "38200 loss: 0.03706770017743111 acc: 0.980625\n",
      "38400 loss: 0.0334138385951519 acc: 0.9790625\n",
      "38600 loss: 0.06359656155109406 acc: 0.9814063\n",
      "38800 loss: 0.08631355315446854 acc: 0.9790625\n",
      "39000 loss: 0.07115783542394638 acc: 0.97828126\n",
      "39200 loss: 0.025479109957814217 acc: 0.9784375\n",
      "39400 loss: 0.029756061732769012 acc: 0.98484373\n",
      "39600 loss: 0.07847161591053009 acc: 0.9828125\n",
      "39800 loss: 0.02396862953901291 acc: 0.9809375\n",
      "40000 loss: 0.10122990608215332 acc: 0.9817188\n",
      "40200 loss: 0.07052213698625565 acc: 0.98125\n",
      "40400 loss: 0.08544144034385681 acc: 0.9796875\n",
      "40600 loss: 0.049777619540691376 acc: 0.9820312\n",
      "40800 loss: 0.12346453964710236 acc: 0.97984374\n",
      "41000 loss: 0.05454516410827637 acc: 0.978125\n",
      "41200 loss: 0.06723948568105698 acc: 0.98296875\n",
      "41400 loss: 0.04633992165327072 acc: 0.985\n",
      "41600 loss: 0.11632466316223145 acc: 0.9809375\n",
      "41800 loss: 0.049562662839889526 acc: 0.9828125\n",
      "42000 loss: 0.038489606231451035 acc: 0.9814063\n",
      "42200 loss: 0.038623832166194916 acc: 0.9821875\n",
      "42400 loss: 0.08276136964559555 acc: 0.9828125\n",
      "42600 loss: 0.09666541963815689 acc: 0.97859377\n",
      "42800 loss: 0.06903652101755142 acc: 0.9821875\n",
      "43000 loss: 0.07080700993537903 acc: 0.98\n",
      "43200 loss: 0.10334622859954834 acc: 0.9859375\n",
      "43400 loss: 0.04586939886212349 acc: 0.9828125\n",
      "43600 loss: 0.04909516125917435 acc: 0.98296875\n",
      "43800 loss: 0.0745365172624588 acc: 0.9817188\n",
      "44000 loss: 0.027461422607302666 acc: 0.9828125\n",
      "44200 loss: 0.15538927912712097 acc: 0.9840625\n",
      "44400 loss: 0.0699850395321846 acc: 0.9815625\n",
      "44600 loss: 0.11798637360334396 acc: 0.98015624\n",
      "44800 loss: 0.04480252414941788 acc: 0.98078126\n",
      "45000 loss: 0.04554542154073715 acc: 0.9859375\n",
      "45200 loss: 0.054622042924165726 acc: 0.9842188\n",
      "45400 loss: 0.0612049400806427 acc: 0.98328125\n",
      "45600 loss: 0.05174480378627777 acc: 0.9845312\n",
      "45800 loss: 0.04641495645046234 acc: 0.983125\n",
      "46000 loss: 0.06730327010154724 acc: 0.98234373\n",
      "46200 loss: 0.06056154891848564 acc: 0.983125\n",
      "46400 loss: 0.05379109084606171 acc: 0.98234373\n",
      "46600 loss: 0.04650180786848068 acc: 0.98125\n",
      "46800 loss: 0.06988532841205597 acc: 0.98328125\n",
      "47000 loss: 0.06352899968624115 acc: 0.986875\n",
      "47200 loss: 0.02507052943110466 acc: 0.98328125\n",
      "47400 loss: 0.06303708255290985 acc: 0.985625\n",
      "47600 loss: 0.057496774941682816 acc: 0.9821875\n",
      "47800 loss: 0.03470860421657562 acc: 0.98484373\n",
      "48000 loss: 0.047835804522037506 acc: 0.9846875\n",
      "48200 loss: 0.0684489756822586 acc: 0.981875\n",
      "48400 loss: 0.04714637249708176 acc: 0.98328125\n",
      "48600 loss: 0.0467822402715683 acc: 0.98109376\n",
      "48800 loss: 0.05534663796424866 acc: 0.985625\n",
      "49000 loss: 0.05651319772005081 acc: 0.986875\n",
      "49200 loss: 0.03467557951807976 acc: 0.98375\n",
      "49400 loss: 0.05799506977200508 acc: 0.9842188\n",
      "49600 loss: 0.08093913644552231 acc: 0.98375\n",
      "49800 loss: 0.050264351069927216 acc: 0.98515624\n",
      "50000 loss: 0.04633311182260513 acc: 0.9834375\n",
      "50200 loss: 0.0859617218375206 acc: 0.98234373\n",
      "50400 loss: 0.108611099421978 acc: 0.98359376\n",
      "50600 loss: 0.020883912220597267 acc: 0.98640627\n",
      "50800 loss: 0.0584995374083519 acc: 0.98578125\n",
      "51000 loss: 0.05538693815469742 acc: 0.9840625\n",
      "51200 loss: 0.07089769840240479 acc: 0.9859375\n",
      "51400 loss: 0.03443470597267151 acc: 0.98390627\n",
      "51600 loss: 0.02728980965912342 acc: 0.9846875\n",
      "51800 loss: 0.025019176304340363 acc: 0.984375\n",
      "52000 loss: 0.029969744384288788 acc: 0.98375\n",
      "52200 loss: 0.16428527235984802 acc: 0.98234373\n",
      "52400 loss: 0.0657745823264122 acc: 0.9840625\n",
      "52600 loss: 0.06908736377954483 acc: 0.98796874\n",
      "52800 loss: 0.0288666021078825 acc: 0.9859375\n",
      "53000 loss: 0.05250703915953636 acc: 0.9870312\n",
      "53200 loss: 0.028832565993070602 acc: 0.98390627\n",
      "53400 loss: 0.02799273654818535 acc: 0.9845312\n",
      "53600 loss: 0.05125605687499046 acc: 0.98609376\n",
      "53800 loss: 0.07142776250839233 acc: 0.984375\n",
      "54000 loss: 0.05321193113923073 acc: 0.9840625\n",
      "54200 loss: 0.02073707804083824 acc: 0.98265624\n",
      "54400 loss: 0.02141815423965454 acc: 0.988125\n",
      "54600 loss: 0.05628116428852081 acc: 0.986875\n",
      "54800 loss: 0.02192075178027153 acc: 0.9875\n",
      "55000 loss: 0.09048745036125183 acc: 0.98625\n",
      "55200 loss: 0.05898883938789368 acc: 0.98546875\n",
      "55400 loss: 0.0704147145152092 acc: 0.9853125\n",
      "55600 loss: 0.04140137881040573 acc: 0.98546875\n",
      "55800 loss: 0.10973145812749863 acc: 0.98484373\n",
      "56000 loss: 0.0463416613638401 acc: 0.983125\n",
      "56200 loss: 0.04962681978940964 acc: 0.9859375\n"
     ]
    }
   ],
   "source": [
    "for step,(x,y) in enumerate(db):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        x = tf.reshape(x,(-1,28*28))\n",
    "        \n",
    "        out = model(x)\n",
    "        \n",
    "        y_onehot = tf.one_hot(y,depth=10)\n",
    "        \n",
    "        loss = tf.square(out-y_onehot)\n",
    "        \n",
    "        loss = tf.reduce_sum(loss) / x.shape[0]\n",
    "        \n",
    "    acc_meter.update_state(tf.argmax(out,axis=1),y)\n",
    "    \n",
    "    grads = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step,'loss:',float(loss),'acc:',acc_meter.result().numpy())\n",
    "        acc_meter.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
